coffee$country_of_origin == "Ecuador" |
coffee$country_of_origin == "Mauritius"|
coffee$country_of_origin == "Papua New Guinea",
names(sort(-table(coffee$variety)))[1], #calcula a moda
coffee$variety)
# Cria uma tabela com a moda de variety por country_of_origin
moda_por_regiao <- coffee %>%
group_by(country_of_origin) %>%
summarise(moda_variety = names(sort(-table(variety)))[1])
moda_por_regiao <- na.omit(moda_por_regiao)
# Substitui os valores ausentes pelo valor mais frequente na região
coffee <- coffee %>%
group_by(country_of_origin) %>%
mutate(variety = ifelse(is.na(variety), moda_por_regiao$moda_variety[match(country_of_origin, moda_por_regiao$country_of_origin)], variety))
sum(is.na(coffee$variety))
#---------------------------------------------------------------------
## não achei a forma de trocar pela mediada ... ainda buscando :(
## Comentário Flávio: resolvi acima
### S2
# Criando a coluna continentes de acordo com o nome do country
## Comentário Flávio: precisamos da uma coluna chamada continente? Fiquei na dúvida
### na ultima versão que eu fiz eu havia retirado, realmente não agrega, vou comentar
#coffee$continent <-
#  countrycode(sourcevar = coffee$country_of_origin,
#              origin = "country.name", destination = "continent")
#---------------------------------------------------------------------
view(coffee)
#Removendo a coluna unit_of_measurement (não precisaremos dela)
coffee <- subset(coffee, select = -c(unit_of_measurement))
#---------------------------------------------------------------------
# não entendo a inclusão de "idade"
## Comentário Flávio: acho que não faz sentido também. Aí deixei comentado.
# Adding a new column called "Age"
#df <- mutate(df, Age = c(25, 30, 22, 28, 35))
#---------------------------------------------------------------------
## Criar a coluna chamada Grade com a classificação dos cafés
## Critério:
## < 70 - Ruim (será 0)
## 70>= e < 80 - Bom (será 1)
## 80>= e < 85 - Muito Bom (será 2)
## 85 >= - Excelente (será 3)
coffee$grade <- cut(coffee$total_cup_points,
breaks = c(-Inf, 70, 80, 85, Inf),
labels = c(0, 1, 2, 3),
right = FALSE)
# Proporção de café por faixa de score
contagem_faixas <- table(coffee$grade)
barplot(prop.table(contagem_faixas) * 100, main = "Porcentagem de Faixa de score",
xlab = "Faixa de score", ylab = "Porcentagem", col = "green")
# Gráfico com o % de variáveis NA
colunas_na <- colSums(is.na(coffee))
info_na <- colunas_na[colunas_na > 0] # 4 colunas com NA
porcent_NA <- info_na / nrow(coffee) * 100
info_na
# Calculando a matriz de correlação
dados <- coffee
colunas_nao_numericas <- sapply(dados, class) != "numeric"
dados_numericos <- dados[, !colunas_nao_numericas]
matrix_de_correlacao <- cor(dados_numericos)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 45)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 100)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 500)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 5)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 5000)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 100)
coffee_grade <- subset(coffee, select = -c(aroma,flavor,
aftertaste,acidity,body,balance,
uniformity,clean_cup,sweetness,
cupper_points))
coffee_cluster <- subset(coffee, select = c(total_cup_points,aroma,flavor,
aftertaste,acidity,body,balance,
uniformity,clean_cup,sweetness,
cupper_points))
view(coffee_grade)
coffee_grade <- subset(coffee, select = -c(total_cup_points,aroma,flavor,
aftertaste,acidity,body,balance,
uniformity,clean_cup,sweetness,
cupper_points))
view(coffee_grade)
set.seed(123)
split <- initial_split(coffee_grade, prop = .70)
treino <- training(split)
teste  <- testing(split)
receita <- recipe(grade ~ ., data = treino) %>%
step_normalize(all_numeric(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes())
(receita_prep <- prep(receita))
treino_proc <- bake(receita_prep, new_data = NULL)
teste_proc <- bake(receita_prep, new_data = teste)
lm <- linear_reg() %>% set_engine("lm")
lm_fit <- linear_reg() %>%
set_engine("lm") %>%
fit(total_cup_points ~ ., treino_proc)
lm_fit <- linear_reg() %>%
set_engine("lm") %>%
fit(grade ~ ., treino_proc)
boost <- boost_tree(trees = tune(), min_n = tune(),
tree_depth = tune(), learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression")
set.seed(123)
cv_split <- vfold_cv(treino, v = 5)
boost_grid <- tune_grid(boost,
receita,
resamples = cv_split,
grid = 30,
metrics = metric_set(rmse, mae))
cv_split <- vfold_cv(treino, v = 5)
boost_grid <- tune_grid(boost,
receita,
resamples = cv_split,
grid = 30,
metrics = metric_set(rmse, mae))
best <- boost_grid %>%
select_best("rmse")
# Calculando a matriz de correlação
dados <- coffee
colunas_nao_numericas <- sapply(dados, class) != "numeric"
dados_numericos <- dados[, !colunas_nao_numericas]
matrix_de_correlacao <- cor(dados_numericos)
options(repr.plot.width = 8, repr.plot.height = 8)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 100)
options(repr.plot.width = 16, repr.plot.height = 16)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 50)
options(repr.plot.width = 32, repr.plot.height = 32)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 50)
# Calculando a matriz de correlação
dados <- coffee_grade
colunas_nao_numericas <- sapply(dados, class) != "numeric"
dados_numericos <- dados[, !colunas_nao_numericas]
matrix_de_correlacao <- cor(dados_numericos)
options(repr.plot.width = 32, repr.plot.height = 32)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 50)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(MASS)
library(tidyverse)
library(keras)
library(rsample)
library(keras)
library(yardstick)
library(skimr)
library(dplyr)
library(GGally)
library(ggrepel)
library(factoextra)
library(countrycode)
library(dplyr)
library(tidymodels)
library(tidyverse)
library(ISLR)
library(vip)
library(doParallel)
library(skimr)
library(corrplot)
library(caret)
```{r}
#conflicts_prefer(dplyr::select)
df <- read.csv("https://raw.githubusercontent.com/mconjaud/TrabalhoFinalAEM2/main/Estatistica/coffee_ratings.csv")
skim(df) # descritiva dos dados
#Não há dados faltantes, logo não é necessário o tratamento para completar a base
summary(df)
colunas_na <- colSums(is.na(df))
info_na <- colunas_na[colunas_na > 0] # 4 colunas com NA
porcent_NA <- info_na / nrow(df) * 100
barplot(porcent_NA, main = "Porcentagem de NA por Coluna",
ylab = "Porcentagem de NA", xlab = "Colunas",
col = "blue", las = 2)  # las = 2 para rotacionar os rótulos do eixo x
coffee <- subset (df,
select = -c(owner
,farm_name
,lot_number
,mill
,ico_number
,company
,altitude
,region
,producer
,number_of_bags
,bag_weight
,in_country_partner
,harvest_year
,grading_date
,owner_1
,expiration
,certification_body
,certification_address
,certification_contact
,altitude_low_meters
,altitude_high_meters))
df <- df[complete.cases(df$country_of_origin), ]
coffee <- subset (df,
select = -c(owner
,farm_name
,lot_number
,mill
,ico_number
,company
,altitude
,region
,producer
,number_of_bags
,bag_weight
,in_country_partner
,harvest_year
,grading_date
,owner_1
,expiration
,certification_body
,certification_address
,certification_contact
,altitude_low_meters
,altitude_high_meters))
coffee <- coffee %>%
mutate(processing_method =
ifelse(is.na(processing_method), "Washed / Wet", processing_method))
coffee <- coffee %>%
mutate(color = ifelse(is.na(color), "Green", color))
coffee<- coffee %>%
mutate(altitude_mean_meters = ifelse(unit_of_measurement == "ft", altitude_mean_meters * 0.3048, altitude_mean_meters))
coffee<- coffee %>%
mutate(altitude_mean_meters = ifelse(altitude_mean_meters > 100000, altitude_mean_meters/100, altitude_mean_meters))
coffee<- coffee %>%
mutate(altitude_mean_meters = ifelse(altitude_mean_meters > 5000, altitude_mean_meters/10, altitude_mean_meters))
coffee <- coffee %>%
group_by(country_of_origin) %>%
mutate(altitude_mean_meters = ifelse(is.na(altitude_mean_meters),
mean(altitude_mean_meters, na.rm = TRUE),
altitude_mean_meters))
coffee$quakers <- ifelse(is.na(coffee$quakers),
names(sort(-table(coffee$quakers)))[1], #calcula a moda
coffee$quakers)
coffee$variety <- ifelse(coffee$country_of_origin == "Cote d?Ivoire" |
coffee$country_of_origin == "Ecuador" |
coffee$country_of_origin == "Mauritius"|
coffee$country_of_origin == "Papua New Guinea",
names(sort(-table(coffee$variety)))[1], #calcula a moda
coffee$variety)
moda_por_regiao <- coffee %>%
group_by(country_of_origin) %>%
summarise(moda_variety = names(sort(-table(variety)))[1])
moda_por_regiao <- na.omit(moda_por_regiao)
coffee <- coffee %>%
group_by(country_of_origin) %>%
mutate(variety = ifelse(is.na(variety), moda_por_regiao$moda_variety[match(country_of_origin, moda_por_regiao$country_of_origin)], variety))
coffee$variety <- ifelse(coffee$variety == "Other" ,
names(sort(-table(coffee$variety)))[1], #calcula a moda
coffee$variety)
coffee <- subset(coffee, select = -c(unit_of_measurement))
coffee$grade <- cut(coffee$total_cup_points,
breaks = c(-Inf, 70, 80, 85, Inf),
labels = c(0, 1, 2, 3),
right = FALSE)
coffee$type <- ifelse(coffee$total_cup_points >= 80, "Very_Good", "Not_Very_Good")
contagem_faixas <- table(coffee$grade)
proporcao <- text(x = barplot(prop.table(contagem_faixas) * 100, main = "Porcentagem de Faixa de score",
xlab = "Faixa de score", ylab = "Porcentagem", col = "green"),
labels = round(prop.table(contagem_faixas)* 100, 1), pos = 3)
dados <- coffee
colunas_nao_numericas <- sapply(dados, class) != "numeric"
dados_numericos <- dados[, !colunas_nao_numericas]
matrix_de_correlacao <- cor(dados_numericos)
options(repr.plot.width = 32, repr.plot.height = 32)
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 50)
coffee_grade <- subset(coffee, select = -c(total_cup_points,aroma,flavor,
aftertaste,acidity,body,balance,
uniformity,clean_cup,sweetness,
cupper_points))
coffee_cluster <- subset(coffee, select = c(aroma,flavor,
aftertaste,acidity,body,balance,
uniformity,clean_cup,sweetness,
cupper_points))
set.seed(123)
split <- initial_split(coffee_grade, prop = 0.8, strata = grade)
training <- training(split)
test <- testing(split)
training_grade <- subset(training, select = -c(type))
test_grade <- subset(test, select = -c(type))
receita <- recipe(grade ~ ., data = training_grade) %>%
step_normalize(all_numeric(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes())
(receita_prep <- prep(receita))
training_proc <- bake(receita_prep, new_data = NULL)
test_proc <- bake(receita_prep, new_data = test_grade)
fit_mr <- multinom_reg(penalty = NULL , mixture = NULL) %>% # define um modelo de regressao Multinomial: pepenalty = 1 lasso \ 2 Ridge
set_engine("nnet") %>%
set_mode("classification") %>%
fit(grade ~ ., training_proc)
fitted <- fit_mr %>%
predict(new_data = test_proc) %>%
mutate(observado = test_proc$grade,
modelo = "Regressao Multinomial")
head(fitted)
matriz_confusao_mr <- confusionMatrix(fitted$.pred_class, fitted$observado)
boost <- boost_tree(trees = tune(), min_n = tune(),
tree_depth = tune(), learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("classification")
set.seed(123)
cv_split <- vfold_cv(training, v = 5)
registerDoParallel()
boost_grid <- tune_grid(boost,
receita,
resamples = cv_split,
grid = 30,
metrics = metric_set(accuracy))
best <- boost_grid %>%
select_best("accuracy")
boost_fit <- finalize_model(boost, parameters = best) %>%
fit(grade ~ ., training_proc)
fitted_bst <- boost_fit %>%
predict(new_data = test_proc) %>%
mutate(observado = test_proc$grade,
modelo = "XGBoost")
fitted <- fitted %>%
bind_rows(fitted_bst)
matriz_confusao_bst <- confusionMatrix(fitted_bst$.pred_class, fitted_bst$observado)
x_train <- training_proc %>%
select(-grade) %>%
as.matrix()
View(x_train)
x_test <- test_proc %>%
select(-grade) %>%
as.matrix()
x_train <- scale(x_train)
x_test <- scale(x_test,
center = attr(x_train, "scaled:center"),
scale = attr(x_train, "scaled:scale"))
y_train <- to_categorical(training_proc$grade)
y_test <- to_categorical(test_proc$grade)
net <- keras_model_sequential() %>%
layer_dense(units = 64,
activation = "relu",
input_shape = ncol(x_train)) %>%
layer_dropout(rate = 0.1) %>% # regularizacao para evitar overfitting
layer_dense(units = 32, activation = "relu") %>%
layer_dropout(rate = 0.1) %>%  # regularizacao para evitar overfitting
layer_dense(units = 16, activation = "relu") %>%
layer_dropout(rate = 0.1) %>%  # regularizacao para evitar overfitting
layer_dense(units = 8, activation = "relu") %>%
layer_dense(units = 4, activation = 'softmax')
summary(net)
net <- compile(net,
loss = 'categorical_crossentropy',
optimizer = "adam", #ver comentario abaixo
metrics = c("accuracy") #pode ser customizada
)
history <- fit(net, x_train, y_train,
batch_size = 24, epochs = 30, # defaults: 32, 10
validation_split = 0.2)
history <- fit(net, x_train, y_train,
batch_size = 24, epochs = 30, # defaults: 32, 10
validation_split = 0.2)
history
plot(history)
pred_net <- net %>% predict(x_test) %>% k_argmax()%>% k_get_value()
fitted_net <- data.frame(.pred_class = factor(pred_net), observado = test_proc$grade, modelo = "Redes Neurais")
fitted <- fitted %>%
bind_rows(fitted_net)
matriz_confusao_net <- confusionMatrix(fitted_net$.pred_class, fitted_net$observado)
training_type <- subset(training, select = -c(grade))
test_type <- subset(test, select = -c(grade))
receita_type <- recipe(type ~ ., data = training_type) %>%
step_normalize(all_numeric(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes())
(receita_type_prep <- prep(receita_type))
training_proc_type <- bake(receita_type_prep, new_data = NULL)
test_proc_type <- bake(receita_type_prep, new_data = test_type)
fit_glm <- logistic_reg() %>% # define um modelo de regressao logistica
set_engine("glm") %>% # define a engine do modelo
set_mode("classification") %>% # define que e'  problema de classificacao
fit(type ~ ., training_proc_type)
fitted_glm <- fit_glm %>%
predict(new_data = test_proc_type) %>%
mutate(observado = test_proc_type$type,
modelo = "logistica")
head(fitted_glm)
fitted <- fitted %>%
bind_rows(fitted_glm)
matriz_confusao_glm <- confusionMatrix(fitted_glm$.pred_class, fitted_glm$observado)
fitted %>%
group_by(modelo) %>%
metrics(truth = observado, estimate = .pred_class)
matriz_confusao_mr
matriz_confusao_bst
matriz_confusao_net
matriz_confusao_glm
# Ajustando data frame
pca <- coffee_cluster %>%
select(is.numeric) %>% # variaveis numericas
prcomp(scale = TRUE, center = TRUE) # aplica PCA
pca$rotation <- -pca$rotation # troca o sinal das cargas
pca$x <- -pca$x # troca o sinal dos scores
Phi <- pca$rotation # matriz de cargas
head(Phi)
Z <- pca$x # matriz de scores
head(Z)
dados_pca <- as.data.frame(Z) # Criando DF para uso no Kmeans
# o grafico abaixo mostra o percentual explicado da variancia de cada componente
fviz_eig(pca, addlabels = TRUE, ncp = 10) +
labs(x = "Componente Principal",
y = "Percentual explicado da variância")
# o grafico abaixo mostra o percentual explicado da variancia de cada componente
fviz_eig(pca, addlabels = TRUE, ncp = 10) +
labs(x = "Componente Principal",
y = "Percentual explicado da variância")
view(PC1) # Flavor
# retorna a primeira e segunda componentes principais do PCA
PC1 <-
abs(pca$rotation[, 1])
PC2 <-
abs(pca$rotation[, 2])
# Gráfico para analise dos cafés nas duas variáveis criados pelo PCA
fviz_pca_biplot(pca, repel = FALSE, xlab = "PC1 - Flavor",
ylab = "PC2 - Sweetness", geom = "point",
alpha.ind = 0.5)
####### APLICANDO O KMEANS
# Executando o método k-means para identificar o número ótimo de clusters entre as variaveis analisadas
fviz_nbclust(coffee_cluster, kmeans, method = "silhouette")
# Analise do numero de clusters
set.seed(123)
k <- 2:20
tibble(k = k) %>%
mutate(w = map_dbl(k, ~ kmeans(coffee_cluster, centers = .x,
nstart = 10)$tot.withinss)) %>%
ggplot(aes(k, w)) +
geom_point() +
scale_x_continuous(breaks = k) +
geom_line()
tibble(k = k) %>%
mutate(w = map_dbl(k, ~ kmeans(coffee_cluster, centers = .x,
nstart = 10)$tot.withinss)) %>% ggplot(aes(k, w)) +
geom_point() +
scale_x_continuous(breaks = k) +
geom_line()
# Especificar k com base no grafico de cotovelo acima
set.seed(123)
(descricao <- dados_pca %>%
mutate(cluster = factor(kmeans(coffee_cluster, centers = 4, nstart = 10)$cluster)))
# Criando Gráfico de grupos
descricao %>%
ggplot(aes(PC1, PC2, color = cluster)) +
geom_point()+geom_text(aes(label = row.names(dados_pca)), vjust = -0.5) +
labs(
x = "PC1 - Flavor",
y = "PC2 - Sweetness",
title = "Análise de Cluster da Qualidade de Café")
k <- 2:20
tibble(k = k) %>%
mutate(w = map_dbl(k, ~ kmeans(coffee_cluster, centers = .x,
nstart = 10)$tot.withinss)) %>% ggplot(aes(k, w)) +
geom_point() +
scale_x_continuous(breaks = k) +
geom_line()
matriz_confusao_mr
matriz_confusao_bst
matriz_confusao_net
matriz_confusao_glm
# Plotando grupos dentro das variáveis criadas no Kmeans
descricao %>%
ggplot(aes(PC1, PC2, color = cluster)) +
geom_point()) +
# Plotando grupos dentro das variáveis criadas no Kmeans
descricao %>%
ggplot(aes(PC1, PC2, color = cluster)) +
geom_point(), vjust = -0.5) +
# Plotando grupos dentro das variáveis criadas no Kmeans
descricao %>%
ggplot(aes(PC1, PC2, color = cluster)) +
geom_point() vjust = -0.5) +
# Plotando grupos dentro das variáveis criadas no Kmeans
descricao %>%
ggplot(aes(PC1, PC2, color = cluster)) +
geom_point()) +
# Plotando grupos dentro das variáveis criadas no Kmeans
descricao %>%
ggplot(aes(PC1, PC2, color = cluster)) +
geom_point() +
labs(
x = "PC1 - Flavor",
y = "PC2 - Sweetness",
title = "Análise de Cluster da Qualidade de Café")
+geom_text(aes(label = row.names(dados_pca))
# Plotando grupos dentro das variáveis criadas no Kmeans
descricao %>%
# Plotando grupos dentro das variáveis criadas
descricao %>%
ggplot(aes(PC1, PC2, color = cluster)) +
geom_point()+geom_text(aes(label = row.names(dados_pca)), vjust = -0.5) +
labs(
x = "PC1 - Flavor",
y = "PC2 - Sweetness",
title = "Análise de Cluster da Qualidade de Café")
# Plotando grupos dentro das variáveis criadas
descricao %>%
ggplot(aes(PC1, PC2, color = cluster)) +
geom_point(), vjust = -0.5) +
# Plotando grupos dentro das variáveis criadas
descricao %>%
ggplot(aes(PC1, PC2, color = cluster)) +
geom_point()+geom_text(aes(label = row.names(dados_pca)), vjust = -0.5) +
labs(
x = "PC1 - Flavor",
y = "PC2 - Sweetness",
title = "Análise de Cluster da Qualidade de Café")
# Plotando grupos dentro das variáveis criadas
descricao %>%
ggplot(aes(PC1, PC2, color = cluster)) +
geom_point() +
labs(
x = "PC1 - Flavor",
y = "PC2 - Sweetness",
title = "Análise de Cluster da Qualidade de Café")
