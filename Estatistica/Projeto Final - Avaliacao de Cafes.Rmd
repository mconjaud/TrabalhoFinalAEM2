---
title: "Avaliação de Cafés"
author: "Flávio Barbosa Shirahige, Hélio Pereira de Oliveira e Michel Maurice Conjaud Neto"
date: "2023-11-24"
output: html_document
---

```{r warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(MASS)
library(rsample)
library(keras)
library(yardstick)
library(GGally)
library(ggrepel)
library(factoextra)
library(countrycode)
library(dplyr)
library(tidymodels)
library(tidyverse)
library(ISLR)
library(vip)
library(doParallel)
library(skimr)
library(corrplot)
library(caret)
```

### Introdução

Inicialmente, o objetivo desse projeto é prever o pontuação/score da avaliação de cafés a partir das demais preditoras do dataset (análise supervisionada) e agrupar os tipos de café a partir da qualidade do café (análise não supervisionada).

No entanto, a pontuação/score final de um café é a simples somatória das notas de cada uma das qualidades avaliadas. Assim, a nota final é simplesmente uma modelo linear das variáveis de qualidades de café, tornando-se um modelo com erro quase zero.

Assim, optou-se por construir um modelo de classificação que tenta prever a qualidade do café para quatro diferentes níveis: ruim, bom,muito bom e excelente. Para tal, não serão utilizadas nesse processo de modelagem as variáveis que compõe a nota final dos café. Logo, visa-se prever a qualidade do café a partir de outras características do mesmo, como local, tipo de café, grão etc.

Nesse projeto será utilizada a base de dados com informações de qualidade de café coletadas das avaliações do Coffee Quality Institute  de Janeiro de 2018. A avaliação dos café é feita a partir de diversas características do café, como acidez, doçura, equilíbrio etc. e é pontuada numa escala de 0 a 100.
Para os modelos supervisionados, foi criada uma variável resposta a partir dessa pontuação, onde:

- Pontuação menor do que 70: Ruim (será considerado como 0)
- Pontuação maior do que 70 e menor do que 80:  Bom (será considerado como 1)
- Pontuação maior do que 80 e menor do que 85: Muito Bom (será considerado como 2)
- Pontuação maior do que 85: Excelente (será considerado como 3)

Esse critério segue o padrão dos principais institutos que avaliam cafés.

Além disso, como forma de comparação com a abordagem multinomial, será criada uma variável resposta para classificar os cafés em dois tipos (bom e ruim) e será aplicado o modelo de regressão logística. Nesta variável resposta, os cafés com pontuação acima de 80 serão será definido como Very Good e os demais como Not Very Good.

Para os modelos Não supervisionados, será aplicado o PCA e o K-means para clusterização e serão consideradas somente as variáveis de qualidade, conforme abaixo. O objetivo é criar grupos de cafés a partir das características avaliadas.

- Aroma grade
- Flavor grade
- Aftertaste grade
- Acidity grade
- Body grade
- Balance grade
- Uniformity grade
- Clean cup grade
- Sweetness grade
- Cupper Points


### Tratamento e Análise Exploratória dos Dados

Inicialmente, serão importados os dados:

```{r}
#conflicts_prefer(dplyr::select)
df <- read.csv("https://raw.githubusercontent.com/mconjaud/TrabalhoFinalAEM2/main/Estatistica/coffee_ratings.csv")
```

O próximo passo é explorar os dados. 
```{r}
skim(df) # descritiva dos dados
#Não há dados faltantes, logo não é necessário o tratamento para completar a base
summary(df)
```

Abaixo, será plotado o gráfico com o percentual de valores faltantes (missing values):

```{r}
colunas_na <- colSums(is.na(df))
info_na <- colunas_na[colunas_na > 0] # 4 colunas com NA
porcent_NA <- info_na / nrow(df) * 100

barplot(porcent_NA, main = "Porcentagem de NA por Coluna", 
        ylab = "Porcentagem de NA", xlab = "Colunas",
        col = "blue", las = 2)  # las = 2 para rotacionar os rótulos do eixo x
```

### Tratamento dos Dados

Inicialmente, serão removidos as linhas com missing values da coluna country_of_origin, pois essa linha tem pouca informação:
```{r}
df <- df[complete.cases(df$country_of_origin), ]

```

O passo seguinte é excluir as variáveis que não serão utilizadas no processo de modelagem. Serão excluídas algumas variáveis categóricas que não trazerem informação relevante para a qualidade do café, especialmente aqueles relacionadas ao produtor, certificador, tamanho do lote e local de produção do café.
Também serão excluídas as variáveis de data (harvest_year, grading_date, expiration), seja pela qualidade das informações, seja pelo número elevado de valores faltantes. Além destas, foram desconsideradas na modelagem as variáveis altitude_low_meters e altitude_high_meters, pois serem informações já constantes na altitude_mean_meters.
No mais, informações que poderiam ser relevantes, mas que possuem baixa qualidade, também foram descartadas: region (muitos valores distintos e com informações em caracteres que não são do alfabeto ocidental).

```{r}
coffee <- subset (df, 
                  select = -c(owner
                              ,farm_name
                              ,lot_number
                              ,mill
                              ,ico_number
                              ,company
                              ,altitude
                              ,region
                              ,producer
                              ,number_of_bags
                              ,bag_weight
                              ,in_country_partner
                              ,harvest_year
                              ,grading_date
                              ,owner_1
                              ,expiration
                              ,certification_body
                              ,certification_address
                              ,certification_contact
                              ,altitude_low_meters
                              ,altitude_high_meters))

```

A próxima etapa é tratar os missing values das variáveis restantes.

Para a variável processing_method, será considerada o valor mais frequente, isto é, "Washed / Wet":

```{r}
coffee <- coffee %>%
  mutate(processing_method = 
           ifelse(is.na(processing_method), "Washed / Wet", processing_method))
```

Para a variável color, os missing values foram substituídos por "green", a moda dessa coluna:

```{r}
coffee <- coffee %>%
  mutate(color = ifelse(is.na(color), "Green", color))
```

Na coluna altitude_mean_meters será necessário tratar os missing values e a depadronização dos valores, uma vez que os mesmos estão em metros (m) ou pés (ft). Inicialmente será convertida a coluna altitude_mean_meters de pés para metros, quando aplicável:

```{r}
coffee<- coffee %>%
  mutate(altitude_mean_meters = ifelse(unit_of_measurement == "ft", altitude_mean_meters * 0.3048, altitude_mean_meters))
```

Além do problema citado acima, também há problema com qualidade da informação, já que existem valores acima dos 10.000 (mais alto que o Everest). Assim, esses valores serão divididos por 100 (valores acima dos 100.000) e por 10 (acima dos 5000), nessa sequência:

```{r}
coffee<- coffee %>%
  mutate(altitude_mean_meters = ifelse(altitude_mean_meters > 100000, altitude_mean_meters/100, altitude_mean_meters))

coffee<- coffee %>%
  mutate(altitude_mean_meters = ifelse(altitude_mean_meters > 5000, altitude_mean_meters/10, altitude_mean_meters))
```

Tratados os dados de altitude_mean_meters, será feito o preenchimento dos missings desta coluna pela média por país:

```{r}
coffee <- coffee %>%
  group_by(country_of_origin) %>%
  mutate(altitude_mean_meters = ifelse(is.na(altitude_mean_meters),
                                       mean(altitude_mean_meters, na.rm = TRUE),
                                       altitude_mean_meters))
```

Para a variável quakers, os missing values foram substituídos pela moda dessa coluna:

```{r}
coffee$quakers <- ifelse(is.na(coffee$quakers),
                         names(sort(-table(coffee$quakers)))[1], #calcula a moda
                         coffee$quakers)
```

Para a variável variety, serão substituídos pelo valor mais frequente (moda) por país (country_of_origin).
No entanto, há exceções: a Costa do Marfim, Equador, Mauricios e Papua Nova Guine só possuem um café avaliado e não possui valores de variety. Para estes, será utilizada a moda da coluna inteira:

```{r}
coffee$variety <- ifelse(coffee$country_of_origin == "Cote d?Ivoire" |
                           coffee$country_of_origin == "Ecuador" |
                           coffee$country_of_origin == "Mauritius"|
                           coffee$country_of_origin == "Papua New Guinea",
                         names(sort(-table(coffee$variety)))[1], #calcula a moda
                         coffee$variety)
```

Agora, será criada uma tabela com a moda de variety por país (country_of_origin):
```{r}
moda_por_regiao <- coffee %>%
  group_by(country_of_origin) %>%
  summarise(moda_variety = names(sort(-table(variety)))[1])

moda_por_regiao <- na.omit(moda_por_regiao)
```

E abaixo serão substituídos os valores ausentes pelo valor mais frequente do país:

```{r}
coffee <- coffee %>%
  group_by(country_of_origin) %>%
  mutate(variety = ifelse(is.na(variety), moda_por_regiao$moda_variety[match(country_of_origin, moda_por_regiao$country_of_origin)], variety))
```

Além disso, para alguns paises estavam com "other" nesta coluna "variety", será colocada a moda da variável 

```{r}
coffee$variety <- ifelse(coffee$variety == "Other" ,
                         names(sort(-table(coffee$variety)))[1], #calcula a moda
                         coffee$variety)
```

Tratada base de dados, será removida a coluna unit_of_measurement, pois não será utilizada nos processos de modelagem supervisionada e não supervisionada.

```{r}
coffee <- subset(coffee, select = -c(unit_of_measurement))
```

### Variável Resposta dos Modelos Supervisionados

Abaixo será criada a coluna com a varável resposta (grade) para a abordagem multinomial, conforme definido acima:

```{r}
coffee$grade <- cut(coffee$total_cup_points,
                                    breaks = c(-Inf, 70, 80, 85, Inf),
                                    labels = c(0, 1, 2, 3),
                                    right = FALSE)
```

E abaixo será criada a coluna com a varável resposta (type) para uso na regressão logística, conforme definido acima:

```{r}
coffee$type <- ifelse(coffee$total_cup_points >= 80, "Very_Good", "Not_Very_Good")
```


### Proporção de Cafés por Faixa de Pontuação (Grade) e Análise de Colinearidade
### Proporção (Grade) 

Abaixo, vamos plotar o gráfico para verificar a proporção de cafés por faixa (grade):

```{r}
contagem_faixas <- table(coffee$grade)

proporcao <- text(x = barplot(prop.table(contagem_faixas) * 100, main = "Porcentagem de Faixa de score",
                 xlab = "Faixa de score", ylab = "Porcentagem", col = "green"), 
      labels = round(prop.table(contagem_faixas)* 100, 1), pos = 3)

proporcao
```

### Analise de Colinearidade 

E em seguida vamos plotar a matriz de correlação das variáveis númericas:

```{r}
# Calculando a matriz de correlação
dados <- coffee
colunas_nao_numericas <- sapply(dados, class) != "numeric"
dados_numericos <- dados[, !colunas_nao_numericas]
matrix_de_correlacao <- cor(dados_numericos)

options(repr.plot.width = 32, repr.plot.height = 32) 
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 50)
```

Verifica-se que há alta correlação entre as variáveis de qualidade e a pontuação final do café (total_cup_point).

### Datasets para a Análise Supervisionada e Não Supervisionada.

Vamos criar dois datasets distintos, conforme definido acima:

- Análise Supervionada: coffee_grade
- Análise Não Supervionada: coffee_cluster

```{r}
coffee_grade <- subset(coffee, select = -c(total_cup_points,aroma,flavor,
                                          aftertaste,acidity,body,balance,
                                          uniformity,clean_cup,sweetness,
                                          cupper_points))

coffee_cluster <- subset(coffee, select = c(aroma,flavor,
                                            aftertaste,acidity,body,balance,
                                            uniformity,clean_cup,sweetness,
                                            cupper_points))
```

Agora, a etapa seguinte é criar os datasets de treinamento e teste que ser"ao utilizados tanto para a abordagem multinomial quanto para a regressão logística:

```{r}
set.seed(123)

split <- initial_split(coffee_grade, prop = 0.8, strata = grade)
training <- training(split)
test <- testing(split)
```


### Análise Supervisionada (Multinomial)

Nesse item serão construídos e analisados os modelos para prever a variável grade. São eles:

- Regressão Multinomial
- XGBoost
- Redes Neurais

Vamos remover a coluna type dos dados de treinamento e teste, já que esta será só utilizada no modelo de regressão logísitica:

```{r}
training_grade <- subset(training, select = -c(type))
test_grade <- subset(test, select = -c(type))
```


O primeiro passo é definir a receita, com a variavel resposta e os dados de treinamento, normalizando todas numericas exceto a variavel resposta e definindo variavel dummy para todas variaveis qualitativas.

```{r}
receita <- recipe(grade ~ ., data = training_grade) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes())
```

Abaixo, vamos preparar a receita definida acima:

```{r}
(receita_prep <- prep(receita))
```

Por fim, obtemos os dados de treinamento e teste processados: 
```{r}
training_proc <- bake(receita_prep, new_data = NULL)
test_proc <- bake(receita_prep, new_data = test_grade)
```

Vamos utilizar a receita preparada acima para aplicar os 4 modelos definidos inicialmente:

### Aplicação dos modelos
### Tidymodels: Regressão MUltinomial

Primeiramente será definido o modelo de regressão multinomial:
```{r}
fit_mr <- multinom_reg(penalty = NULL , mixture = NULL) %>% # define um modelo de regressao Multinomial: pepenalty = 1 lasso \ 2 Ridge
  set_engine("nnet") %>% 
  set_mode("classification") %>% 
  fit(grade ~ ., training_proc)


```

Aplicando o modelo de previsão nos dados de teste e estimando os dados de previsão, armazenando os resultados do modelo numa tabela chamada fitted:

```{r}
fitted <- fit_mr %>% 
  predict(new_data = test_proc) %>% 
  mutate(observado = test_proc$grade, 
         modelo = "Regressao Multinomial") 

head(fitted)

```

E por último vamos definir a matriz de confusão desse modelo de regressão multinomial:
```{r}
matriz_confusao_mr <- confusionMatrix(fitted$.pred_class, fitted$observado)
```


### Tidymodels: XGBoost

O próximo modelo a ser estimado é o XGBoost. Inicialmente é definir o modelo e quais hiperparâmetros serão otimizados (trees = número de árvores, min_n = valor mínimo por nó, tree_depth = profundidade da árvore e learn_rate = taxa de aprendizagem do modelo):

```{r}
boost <- boost_tree(trees = tune(), min_n = tune(), 
                    tree_depth = tune(), learn_rate = tune()) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")
```

Para esse processo de escolha dos hiperparâmetros, será utilizada a validação cruzada em 5 lotes:

```{r}
set.seed(123)

cv_split <- vfold_cv(training, v = 5)
registerDoParallel()
```


Para esse processo de escolha dos hiperparâmetros, também será utilizada a validação cruzada em 5 lotes. A seguir, serão escolhidos os valores de hiperparâmetros para os melhores acurácia a partir de um grid de 5:

```{r}
boost_grid <- tune_grid(boost, 
                        receita, 
                        resamples = cv_split, 
                        grid = 30, 
                        metrics = metric_set(accuracy))

best <- boost_grid %>% 
  select_best("accuracy")
```

Por fim será aplicado o modelo de previsão nos dados de teste e estimado os dados de previsão, armazenando numa tabela chamada fitted:

```{r}
boost_fit <- finalize_model(boost, parameters = best) %>% 
  fit(grade ~ ., training_proc)

fitted_bst <- boost_fit %>% 
  predict(new_data = test_proc) %>% 
  mutate(observado = test_proc$grade, 
         modelo = "XGBoost")

fitted <- fitted %>% 
  bind_rows(fitted_bst)

```

E finalmente vamos definir a matriz de confusão desse modelo XGBoost:
```{r}
matriz_confusao_bst <- confusionMatrix(fitted_bst$.pred_class, fitted_bst$observado)
```


### Redes Neurais

O último modelo a ser estimado é o de Redes Neurais. Inicialmente, vamos transformar as variáveis preditoras de treinamento e teste em matriz:

```{r}
x_train <- training_proc %>% 
  select(-grade) %>% 
  as.matrix()

View(x_train)

x_test <- test_proc %>% 
  select(-grade) %>% 
  as.matrix()

x_train <- scale(x_train)

x_test <- scale(x_test,
               center = attr(x_train, "scaled:center"),
               scale = attr(x_train, "scaled:scale"))
```

Em seguida, a variável respost será transformada em categórica:  

```{r}
y_train <- to_categorical(training_proc$grade)
y_test <- to_categorical(test_proc$grade)
```

Abaixo foi criada a estrutura da rede desse modelo, com quatro camadas intermediárias e a última com 4 unidades (4 valores de variável resposta esperados):

```{r}
net <- keras_model_sequential() %>% 
  layer_dense(units = 64, 
              activation = "relu", 
              input_shape = ncol(x_train)) %>% 
  layer_dropout(rate = 0.1) %>% # regularizacao para evitar overfitting
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dropout(rate = 0.1) %>%  # regularizacao para evitar overfitting
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dropout(rate = 0.1) %>%  # regularizacao para evitar overfitting
  layer_dense(units = 8, activation = "relu") %>% 
  layer_dense(units = 4, activation = 'softmax')

summary(net)
```

Compilando essa rede:

```{r}
net <- compile(net,
               loss = 'categorical_crossentropy', 
               optimizer = "adam", #ver comentario abaixo
               metrics = c("accuracy") #pode ser customizada
)
```

e treinando o modelo:

```{r}
history <- fit(net, x_train, y_train,
               batch_size = 24, epochs = 30, # defaults: 32, 10
               validation_split = 0.2)

history
plot(history)

```

Por último, vamos aplicar o modelo definido acima nos dados de teste e estimar os dados de previsão, armazenando numa tabela chamada fitted:

```{r}
pred_net <- net %>% predict(x_test) %>% k_argmax()%>% k_get_value()

fitted_net <- data.frame(.pred_class = factor(pred_net), observado = test_proc$grade, modelo = "Redes Neurais")

fitted <- fitted %>% 
  bind_rows(fitted_net)
```

E abaixo vamos definir a matriz de confusão desse modelo de redes neurais:
```{r}
matriz_confusao_net <- confusionMatrix(fitted_net$.pred_class, fitted_net$observado)
```


### Análise Supervisionada (Logística)

Nesse item será estimado e analisado o modelo de regressão logística para prever a variável type. Inicialmente vamos remover a coluna grade dos dados de treinamento e teste, já que foi utilizada na abordagem multinomial:

Vamos remover a coluna type dos dados de treinamento e teste, já que esta será só utilizada no modelo de regressão logísitica:

```{r}
training_type <- subset(training, select = -c(grade))
test_type <- subset(test, select = -c(grade))
```


O primeiro passo é definir a receita, com a variavel resposta e os dados de treinamento, normalizando todas numericas exceto a variavel resposta e definindo variavel dummy para todas variaveis qualitativas.

```{r}
receita_type <- recipe(type ~ ., data = training_type) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes())
```

Abaixo, vamos preparar a receita definida acima:

```{r}
(receita_type_prep <- prep(receita_type))
```

Por fim, obtemos os dados de treinamento e teste processados: 
```{r}
training_proc_type <- bake(receita_type_prep, new_data = NULL)
test_proc_type <- bake(receita_type_prep, new_data = test_type)
```

A seguir será definido o modelo de regressão logística:
```{r}
fit_glm <- logistic_reg() %>% # define um modelo de regressao logistica
  set_engine("glm") %>% # define a engine do modelo
  set_mode("classification") %>% # define que e'  problema de classificacao
  fit(type ~ ., training_proc_type)

```

Aplicando o modelo de previsão nos dados de teste e estimando os dados de previsão, armazenando os resultados do modelo numa tabela chamada fitted:

```{r}
fitted_glm <- fit_glm %>% 
  predict(new_data = test_proc_type) %>% 
  mutate(observado = test_proc_type$type,
         modelo = "logistica")

head(fitted_glm)

fitted <- fitted %>% 
  bind_rows(fitted_glm)

```

E por último vamos definir a matriz de confusão desse modelo de regressão multinomial:
```{r}
matriz_confusao_glm <- confusionMatrix(fitted_glm$.pred_class, fitted_glm$observado)
```

### Avaliação dos Modelos Supervisionados
### Niveis de Acuracia e KAP 

Os resultados finais dos modelos acima estimados com tidymodels e regressão logísitica estão abaixo:

```{r}
fitted %>% 
  group_by(modelo) %>% 
  metrics(truth = observado, estimate = .pred_class)
```

### Matrizes de confusão dos 4 modelos

E abaixo seguem os resultados das matrizes de confusão para cada modelo, bem como o gráfico da proporção dos tipos de café:

Observamos que a análise multinomial se saiu melhor nos acertos, porém, vale salientar que nenhum modelo foi capaz de ter acertos significativos nos grades 0,1 e 3.

Isso se dá por:
Quantidade de casos na base (0 = 0,6% / 1 = 13,3% / 3 = 7,9%)
Com isso as respostas convergem para a grade 2 (Muito bom), mesmo utilizando o Strata na separação de treino de teste.

```{r}
# Matrizes que utilizam a variável Grade (4 saídas)

matriz_confusao_bst$table # 1º em acertos
matriz_confusao_mr$table #2º em acertos
matriz_confusao_net$table #3º em acertos

```
```{r}

# Matriz de confusão modelo Logistico 

matriz_confusao_glm$table # Analise logística 

```

### Análise Não Supervisionada
## PCA

# Gráfico de variância 

Nesta etapa vamos rodar o PCA para verificar a quantidade de variáveis que somam >= 75% da variância.
Neste caso, duas variáveis somam 74%, sendo a primeira 61%, isso já era esperado devido a alta colinearidade das informações, fato esse, explicado no gráfico acima.

```{r}

# PCA seleciona a qtd de variaveis que soma 80% da variancia

# Data frame sem a variavel resposta
view(coffee_cluster)

# Ajustando data frame
pca <- coffee_cluster %>%
  select(is.numeric) %>% # variaveis numericas
  prcomp(scale = TRUE, center = TRUE) # aplica PCA


pca$rotation <- -pca$rotation # troca o sinal das cargas
pca$x <- -pca$x # troca o sinal dos scores

Phi <- pca$rotation # matriz de cargas
head(Phi)

Z <- pca$x # matriz de scores
head(Z)
dados_pca <- as.data.frame(Z) # Criando DF para uso no Kmeans

# o grafico abaixo mostra o percentual explicado da variancia de cada componente
fviz_eig(pca, addlabels = TRUE, ncp = 10) + 
  labs(x = "Componente Principal",
       y = "Percentual explicado da variância")

```
# Gráfico de variáveis novas explicando os cafés 

Após encontrar as variáveis que explicam 75% da variância (PC1 e PC2), vamos nomeá-las e ver como os cafés se comportam de acordo com cada uma delas.

Optamos por limitar os eixos X e Y do gráfico abaixo, retirando assim os outiers e melhor mostrando a dispersão. 

É observado 3 divisões lineares no gráfico abaixo: 
1 - Cafés que buscam doçura e sabor
2 - Cafés que buscam maior intensidade de sabor
3 - Café que buscam maior doçura 


```{r}
# retorna a primeira e segunda componentes principais do PCA
PC1 <- 
  abs(pca$rotation[, 1])
view(PC1) # Flavor

PC2 <- 
  abs(pca$rotation[, 2])
view(PC2) #sweetness

# Gráfico para analise dos cafés nas duas variáveis criados pelo PCA
fviz_pca_biplot(pca, repel = FALSE, xlab = "PC1 - Flavor", 
                ylab = "PC2 - Sweetness", geom = "point", 
                alpha.ind = 0.5)  +
  xlim(c(-10, 15)) +
  ylim(c(-10, 10))

```

## Kmeans
# Gráfico de número ótimo de clusters

```{r}
# Executando o método k-means para identificar o número ótimo de clusters entre as variaveis analisadas
fviz_nbclust(coffee_cluster, kmeans, method = "silhouette")

```
# Gráfico de cotovelo

```{r}
# Analise do Gráfico de cotovelo
set.seed(123)

k <- 2:20

tibble(k = k) %>% 
  mutate(w = map_dbl(k, ~ kmeans(coffee_cluster, centers = .x,
                                 nstart = 10)$tot.withinss)) %>% ggplot(aes(k, w)) + 
  geom_point() + 
  scale_x_continuous(breaks = k) +
  geom_line()

```
# Gráfico dos 4 clusters da qualidade do café 

Para finalizar a anlise não supervisionada, rodamos o Kmeans com 4 cluster (gráfico de cotovelo acima) para identificar como cada cafeicultor escolhe a qualidade da sua safra. 

Optamos por limitar os eixos X e Y do gráfico abaixo, retirando assim os outliers e melhor mostrando a dispersão.

Após limitar os eixos, fica mais fácil de identificar a linearidade dos grupos 2 e 4 e a dispersão dos grupos 1 e 3. 

Os grupos 1 e 3 tentam buscar ambos os indicadores de qualidade (PC1 e PC2) para seu café. Enquanto os 2 e 4 são bem distintos em suas escolhas na hora do plantio.

O grupo 1, por outro lado, busca se diferenciar ainda mais, sendo o grupo com mais outliers. 

Essas escolhas poderiam, em uma análise futura, ser explicadas pela região, altitude e tipo do café. 


```{r}
# Especificar k com base no grafico de cotovelo acima
set.seed(123)

(descricao <- dados_pca %>% 
    mutate(cluster = factor(kmeans(coffee_cluster, centers = 4, nstart = 10)$cluster)))

knitr::kable(head(descricao, 10))

# Plotando grupos dentro das variáveis criadas
descricao %>% 
  ggplot(aes(PC1, PC2, color = cluster)) + 
  geom_point() + 
  labs(
    x = "PC1 - Flavor",
    y = "PC2 - Sweetness",
    title = "Análise de Cluster da Qualidade de Café")  +
  xlim(c(-10, 10)) +
  ylim(c(-5, 10))

```