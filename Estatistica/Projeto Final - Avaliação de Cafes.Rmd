---
title: "Avaliação de Cafés"
author: "Flávio Barbosa Shirahige, Hélio Pereira de Oliveira e Michel Maurice Conjaud Neto"
date: "2023-11-24"
output: html_document
---

```{r warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(tidyverse)
library(keras)
library(rsample)
library(keras)
library(yardstick)
library(skimr)
library(dplyr)
library(GGally)
library(ggrepel)
library(factoextra)
library(countrycode)
library(dplyr)
library(tidymodels)
library(tidyverse)
library(ISLR)
library(vip)
library(doParallel)
library(skimr)
library(corrplot)
```

## Introdução

Inicialmente, o objetivo desse projeto é prever o pontuação/score da avaliação de cafés a partir das demais preditoras do dataset (análise supervisionada) e agrupar os tipos de café a partir da qualidade do café (análise não supervisionada).

No entanto, a pontuação/score final de um café é a simples somatória das notas de cada uma das qualidades avaliadas. Assim, a nota final é simplesmente uma modelo linear das variáveis de qualidades de café, tornando-se um modelo com erro quase zero.

Assim, optou-se por construir um modelo de classificação que tenta prever a qualidade do café para quatro diferentes níveis: ruim, bom,muito bom e excelente. Para tal, não serão utilizadas nesse processo de modelagem as variáveis que compõe a nota final dos café. Logo, visa-se prever a qualidade do café a partir de outras características do mesmo, como local, tipo de café, grão etc.

Nesse projeto será utilizada a base de dados com informações de qualidade de café coletadas das avaliações do Coffee Quality Institute  de Janeiro de 2018. A avaliação dos café é feita a partir de diversas características do café, como acidez, doçura, equilíbrio etc. e é pontuada numa escala de 0 a 100.
Para os modelos supervisionados, foi criada uma variável resposta a partir dessa pontuação, onde:

- Pontuação menor do que 70: Ruim (será considerado como 0)
- Pontuação maior do que 70 e menor do que 80:  Bom (será considerado como 1)
- Pontuação maior do que 80 e menor do que 85: Muito Bom (será considerado como 2)
- Pontuação maior do que 85: Excelente (será considerado como 3)

Essa critério segue o padrão dos principais institutos que avaliam cafés.

Para os modelos supervisionados, será aplicado o PCA e o K-means para clusterização e serão consideradas somente as variáveis de qualidade, conforme abaixo. O objetivo é criar grupos de cafés a partir das características avaliadas.

- Aroma grade
- Flavor grade
- Aftertaste grade
- Acidity grade
- Body grade
- Balance grade
- Uniformity grade
- Clean cup grade
- Sweetness grade
- Cupper Points



## Tratamento e Análise Exploratória dos Dados

Inicialmente, serão importados os dados:

```{r}
#conflicts_prefer(dplyr::select)
df <- read.csv("https://raw.githubusercontent.com/mconjaud/TrabalhoFinalAEM2/main/Estatistica/coffee_ratings.csv")
```

O próximo passo é explorar os dados. 
```{r}
skim(df) # descritiva dos dados
#Não há dados faltantes, logo não é necessário o tratamento para completar a base
summary(df)
```

Abaixo, será plotado o gráfico com o percentual de valores faltantes (missing values):

```{r}
colunas_na <- colSums(is.na(df))
info_na <- colunas_na[colunas_na > 0] # 4 colunas com NA
porcent_NA <- info_na / nrow(df) * 100

barplot(porcent_NA, main = "Porcentagem de NA por Coluna", 
        ylab = "Porcentagem de NA", xlab = "Colunas",
        col = "blue", las = 2)  # las = 2 para rotacionar os rótulos do eixo x
```

### Tratamento dos Dados

Inicialmente, serão removidos as linhas com missing values da coluna country_of_origin, pois essa linha tem pouca informação:
```{r}
df <- df[complete.cases(df$country_of_origin), ]
```

O passo seguinte é excluir as variáveis que não serão utilizadas no processo de modelagem. Serão excluídas algumas variáveis categóricas que não trazerem informação relevante para a qualidade do café, especialmente aqueles relacionadas ao produtor, certificador, tamanho do lote e local de produção do café.
Também serão excluídas as variáveis de data (harvest_year, grading_date, expiration), seja pela qualidade das informações, seja pelo número elevado de valores faltantes. Além destas, foram desconsideradas na modelagem as variáveis altitude_low_meters e altitude_high_meters, pois serem informações já constantes na altitude_mean_meters.
No mais, informações que poderiam ser relevantes, mas que possuem baixa qualidade, também foram descartadas: region (muitos valores distintos e com informações em caracteres que não são do alfabeto ocidental).

```{r}
coffee <- subset (df, 
                  select = -c(owner
                              ,farm_name
                              ,lot_number
                              ,mill
                              ,ico_number
                              ,company
                              ,altitude
                              ,region
                              ,producer
                              ,number_of_bags
                              ,bag_weight
                              ,in_country_partner
                              ,harvest_year
                              ,grading_date
                              ,owner_1
                              ,expiration
                              ,certification_body
                              ,certification_address
                              ,certification_contact
                              ,altitude_low_meters
                              ,altitude_high_meters))
```

A próxima etapa é tratar os missing values das variáveis restantes.
Para a variável processing_method, será considerada o valor mais frequente, isto é, "Washed / Wet":

```{r}
coffee <- coffee %>%
  mutate(processing_method = 
           ifelse(is.na(processing_method), "Washed / Wet", processing_method))
```

Para a variável color, os missing values foram substituídos por "green", a moda dessa coluna:

```{r}
coffee <- coffee %>%
  mutate(color = ifelse(is.na(color), "Green", color))
```

Na coluna altitude_mean_meters será necessário tratar os missing values e a depadronização dos valores, uma vez que os mesmos estão em metros (m) ou pés (ft). Inicialmente será convertida a coluna altitude_mean_meters de pés para metros, quando aplicável:

```{r}
coffee<- coffee %>%
  mutate(altitude_mean_meters = ifelse(unit_of_measurement == "ft", altitude_mean_meters * 0.3048, altitude_mean_meters))
```

Além do problema citado acima, também há problema com qualidade da informação, já que existem valores acima dos 10.000 (mais alto que o Everest). Assim, esses valores serão divididos por 100 (valores acima dos 100.000) e por 10 (acima dos 5000), nessa sequência:

```{r}
coffee<- coffee %>%
  mutate(altitude_mean_meters = ifelse(altitude_mean_meters > 100000, altitude_mean_meters/100, altitude_mean_meters))

coffee<- coffee %>%
  mutate(altitude_mean_meters = ifelse(altitude_mean_meters > 5000, altitude_mean_meters/10, altitude_mean_meters))
```

Tratados os dados de altitude_mean_meters, será feito o preenchimento dos missings desta coluna pela média por país:

```{r}
coffee <- coffee %>%
  group_by(country_of_origin) %>%
  mutate(altitude_mean_meters = ifelse(is.na(altitude_mean_meters),
                                       mean(altitude_mean_meters, na.rm = TRUE),
                                       altitude_mean_meters))
```

Para a variável quakers, os missing values foram substituídos pela moda dessa coluna:

```{r}
coffee$quakers <- ifelse(is.na(coffee$quakers),
                         names(sort(-table(coffee$quakers)))[1], #calcula a moda
                         coffee$quakers)
```

Para a variável variety, serão substituídos pelo valor mais frequente (moda) por país (country_of_origin).
No entanto, há exceções: a Costa do Marfim, Equador, Mauricios e Papua Nova Guine só possuem um café avaliado e não possui valores de variety. Para estes, será utilizada a moda da coluna inteira:

```{r}
coffee$variety <- ifelse(coffee$country_of_origin == "Cote d?Ivoire" |
                           coffee$country_of_origin == "Ecuador" |
                           coffee$country_of_origin == "Mauritius"|
                           coffee$country_of_origin == "Papua New Guinea",
                         names(sort(-table(coffee$variety)))[1], #calcula a moda
                         coffee$variety)
```

Agora, será criada uma tabela com a moda de variety por país (country_of_origin):
```{r}
moda_por_regiao <- coffee %>%
  group_by(country_of_origin) %>%
  summarise(moda_variety = names(sort(-table(variety)))[1])

moda_por_regiao <- na.omit(moda_por_regiao)
```

E abaixo serão substituídos os valores ausentes pelo valor mais frequente do país:

```{r}
coffee <- coffee %>%
  group_by(country_of_origin) %>%
  mutate(variety = ifelse(is.na(variety), moda_por_regiao$moda_variety[match(country_of_origin, moda_por_regiao$country_of_origin)], variety))
```

Além disso, para alguns paises estavam com "other" nesta coluna "variety", será colocada a moda da variável 

```{r}
coffee$variety <- ifelse(coffee$variety == "Other" ,
                         names(sort(-table(coffee$variety)))[1], #calcula a moda
                         coffee$variety)
```

Tratada base de dados, será removida a coluna unit_of_measurement, pois não será utilizada nos processos de modelagem supervisionada e não supervisionada.

```{r}
coffee <- subset(coffee, select = -c(unit_of_measurement))
```

### Variável Resposta dos Modelos Supervisionados

Abaixo será criada a coluna com a varável resposta (grade), conforme definido acima:

```{r}
coffee$grade <- cut(coffee$total_cup_points,
                                    breaks = c(-Inf, 70, 80, 85, Inf),
                                    labels = c(0, 1, 2, 3),
                                    right = FALSE)
```


### Proporção de Cafés por Faixa de Pontuação (Grade) e Análise de Colinearidade

#### Propoção

Abaixo, vamos plotar o gráfico para verificar a proporção de cafés por faixa (grade):

```{r}
contagem_faixas <- table(coffee$grade)

barplot(prop.table(contagem_faixas) * 100, main = "Porcentagem de Faixa de score",
        xlab = "Faixa de score", ylab = "Porcentagem", col = "green")
```

#### Analise de Colinearidade 

E em seguida vamos plotar a matriz de correlação das variáveis númericas:

```{r}
# Calculando a matriz de correlação
dados <- coffee
colunas_nao_numericas <- sapply(dados, class) != "numeric"
dados_numericos <- dados[, !colunas_nao_numericas]
matrix_de_correlacao <- cor(dados_numericos)

options(repr.plot.width = 32, repr.plot.height = 32) 
corrplot(matrix_de_correlacao, method = "color", type = "upper", tl.col = "black", tl.srt = 50)
```

Verifica-se que há alta correlação entre as variáveis de qualidade e a pontuação final do café (total_cup_point).

### Datasets para a Análise Supervisionada e Não Supervisionada.

Vamos criar dois datasets distintos, conforme definido acima:

- Análise Supervionada: coffee_grade
- Análise Supervionada: coffee_cluster
```{r}
coffee_grade <- subset(coffee, select = -c(total_cup_points,aroma,flavor,
                                          aftertaste,acidity,body,balance,
                                          uniformity,clean_cup,sweetness,
                                          cupper_points))

  coffee_cluster <- subset(coffee, select = c(aroma,flavor,
                                            aftertaste,acidity,body,balance,
                                            uniformity,clean_cup,sweetness,
                                            cupper_points))
```


## Análise Supervisionada

Nesse item serão construídos e analisados os modelos para prever os preços dos alugueis. São eles:

- Regressão Multinomial
- XGBoost
- Redes Neurais


Agora, a etapa seguinte é criar os datasets de treinamento e teste:

```{r}
set.seed(123)
split <- initial_split(coffee_grade, prop = 0.8, strata = grade)
training <- training(split)
test <- testing(split)
```


O primeiro passo é definir a receita, com a variavel resposta e os dados de treinamento, normalizando todas numericas exceto a variavel resposta e definindo variavel dummy para todas variaveis qualitativas.

```{r}
receita <- recipe(grade ~ ., data = training) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes())
```

Abaixo, vamos preparar a receita definida acima:

```{r}
(receita_prep <- prep(receita))
```

Por fim, obtemos os dados de treinamento e teste processados: 
```{r}
training_proc <- bake(receita_prep, new_data = NULL)
test_proc <- bake(receita_prep, new_data = test)
```

Vamos utilizar a receita preparada acima para aplicar os 4 modelos definidos inicialmente:

### Tidymodels: Regressão MUltinomial

Primeiramente será estimado o modelo de regressão multinomial:
```{r}
fit_mr <- multinom_reg(penalty = 1, mixture = NULL) %>% # define um modelo de regressao Multinomial: pepenalty = 1 lasso \ 2 Ridge
  set_engine("nnet") %>% 
  set_mode("classification") %>% 
  fit(grade ~ ., training_proc)


```

Aplicando o modelo de previsão nos dados de teste e estimando os dados de previsão, armazenando os resultados do modelo numa tabela chamada fitted:

```{r}
fitted <- fit_mr %>% 
  predict(new_data = test_proc) %>% 
  mutate(observado = test_proc$grade, 
         modelo = "Regressao Multinomial") 

head(fitted)

```


### Tidymodels: XGBoost

O último modelo a ser estimado é o XGBoost. Inicialmente é definir o modelo e quais hiperparâmetros serão otimizados (trees = número de árvores, min_n = valor mínimo por nó, tree_depth = profundidade da árvore e learn_rate = taxa de aprendizagem do modelo):

```{r}
boost <- boost_tree(trees = tune(), min_n = tune(), 
                    tree_depth = tune(), learn_rate = tune()) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")
```

Para esse processo de escolha dos hiperparâmetros, será utilizada a validação cruzada em 5 lotes:

```{r}
set.seed(123)
cv_split <- vfold_cv(training, v = 5)
registerDoParallel()
```


Para esse processo de escolha dos hiperparâmetros, também será utilizada a validação cruzada em 5 lotes. A seguir, serão escolhidos os valores de hiperparâmetros para os melhores acurácia a partir de um grid de 5:

```{r}
boost_grid <- tune_grid(boost, 
                        receita, 
                        resamples = cv_split, 
                        grid = 30, 
                        metrics = metric_set(accuracy))

best <- boost_grid %>% 
  select_best("accuracy")
```

Por fim será aplicado o modelo de previsão nos dados de teste e estimado os dados de previsão, armazenando numa tabela chamada fitted:

```{r}
boost_fit <- finalize_model(boost, parameters = best) %>% 
  fit(grade ~ ., training_proc)

fitted_bst <- boost_fit %>% 
  predict(new_data = test_proc) %>% 
  mutate(observado = test_proc$grade, 
         modelo = "XGBoost")

fitted <- fitted %>% 
  bind_rows(fitted_bst)

```


### Redes Neurais

O último modelo a ser estimado é o de Rede Neurais. Inicialmente, vamos transformar as variáveis preditoras de treinamento e teste em matriz:

```{r}
x_train <- training_proc %>% 
  select(-grade) %>% 
  as.matrix()

View(x_train)

x_test <- test_proc %>% 
  select(-grade) %>% 
  as.matrix()

x_train <- scale(x_train)

x_test <- scale(x_test,
               center = attr(x_train, "scaled:center"),
               scale = attr(x_train, "scaled:scale"))
```

Em seguida, a variável respost será transformada em categórica:  

```{r}
y_train <- to_categorical(training_proc$grade)
y_test <- to_categorical(test_proc$grade)
```

Abaixo foi criada a estrutura da rede desse modelo, com quatro camadas intermediárias e a última com 4 unidades (4 valores de variável resposta esperados):

```{r}
net <- keras_model_sequential() %>% 
  layer_dense(units = 64, 
              activation = "relu", 
              input_shape = ncol(x_train)) %>% 
  layer_dropout(rate = 0.1) %>% # regularizacao para evitar overfitting
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dropout(rate = 0.1) %>%  # regularizacao para evitar overfitting
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dropout(rate = 0.1) %>%  # regularizacao para evitar overfitting
  layer_dense(units = 8, activation = "relu") %>% 
  layer_dense(units = 4, activation = 'softmax')

summary(net)
```

Compilando essa rede:

```{r}
net <- compile(net,
               loss = 'categorical_crossentropy', 
               optimizer = "adam", #ver comentario abaixo
               metrics = c("accuracy") #pode ser customizada
)
```

e treinando o modelo:

```{r}
history <- fit(net, x_train, y_train,
               batch_size = 24, epochs = 30, # defaults: 32, 10
               validation_split = 0.2)

history
plot(history)

```

Por último, vamos aplicar o modelo definido acima nos dados de teste e estimar os dados de previsão, armazenando numa tabela chamada fitted:

```{r}
pred_net <- net %>% predict(x_test) %>% k_argmax()%>% k_get_value()

fitted_net <- data.frame(.pred_class = factor(pred_net), observado = test_proc$grade, modelo = "Redes Neurais")

fitted <- fitted %>% 
  bind_rows(fitted_net)
```


### Avaliação dos Modelos Supervisionados

Por último, os resultados finais dos modelos acima estimados com tidymodels estão abaixo:

```{r}
fitted %>% 
  group_by(modelo) %>% 
  metrics(truth = observado, estimate = .pred_class)
```